{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa9dc22",
   "metadata": {
    "id": "2fa9dc22"
   },
   "source": [
    "### Assignment-02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35410eea",
   "metadata": {
    "id": "35410eea"
   },
   "source": [
    "1. What is the distribution of accident severity levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-8fXi_9jWKwT",
   "metadata": {
    "id": "-8fXi_9jWKwT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup: Load Dataset Once ---\n",
    "# NOTE: Replace the file path with the actual location of your 'US_Accidents_March23.csv' file.\n",
    "try:\n",
    "    df = pd.read_csv(\"C:/Users/win10/Desktop/US_Accidents_March23.csv\")\n",
    "    df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "    df['Hour'] = df['Start_Time'].dt.hour\n",
    "    df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "    print(\"Dataset loaded and time features extracted.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: Dataset file not found. Using a small sample DataFrame for demonstration.\")\n",
    "    data = {'Severity': [1, 2, 2, 3, 4, 2, 1, 2],\n",
    "            'Start_Time': pd.to_datetime(['2023-01-01 08:00:00', '2023-01-01 17:00:00', '2023-01-02 01:00:00', '2023-01-02 12:00:00', '2023-01-03 07:30:00', '2023-01-04 08:30:00', '2023-01-05 18:00:00', '2023-01-06 17:30:00']),\n",
    "            'Weather_Condition': ['Clear', 'Rain', 'Clear', 'Clear', 'Clear', 'Heavy Rain', 'Clear', 'Clear'],\n",
    "            'Sunrise_Sunset': ['Day', 'Day', 'Night', 'Day', 'Day', 'Day', 'Day', 'Day'],\n",
    "            'Roundabout': [False, True, False, False, False, True, False, False]}\n",
    "    df = pd.DataFrame(data)\n",
    "    df['Hour'] = df['Start_Time'].dt.hour\n",
    "    df['DayOfWeek'] = df['Start_Time'].dt.dayofweek\n",
    "\n",
    "# --- Question 1 Code ---\n",
    "severity_counts = df['Severity'].value_counts().sort_index()\n",
    "print(\"Severity Counts:\")\n",
    "print(severity_counts)\n",
    "\n",
    "# Visualization\n",
    "fig_severity = px.bar(\n",
    "    x=severity_counts.index,\n",
    "    y=severity_counts.values,\n",
    "    title=\"Accident Severity Distribution\",\n",
    "    labels={\"x\": \"Accident Severity\", \"y\": \"Count\"},\n",
    "    color=severity_counts.index.astype(str),\n",
    "    color_discrete_sequence=px.colors.qualitative.Bold\n",
    ")\n",
    "fig_severity.update_layout(xaxis=dict(tickmode='linear', dtick=1))\n",
    "fig_severity.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3c3f1",
   "metadata": {
    "id": "61b3c3f1"
   },
   "source": [
    "2. How is the accident frequency distributed by hour of the day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a561570",
   "metadata": {
    "id": "8a561570"
   },
   "outputs": [],
   "source": [
    "# --- Question 2 Code ---\n",
    "print(\"\\n### 2. Accident Frequency by Hour of the Day\")\n",
    "hourly_counts = df['Hour'].value_counts().sort_index()\n",
    "print(\"Hourly Accident Counts:\")\n",
    "print(hourly_counts)\n",
    "\n",
    "# Visualization\n",
    "fig_hourly = px.line(\n",
    "    x=hourly_counts.index,\n",
    "    y=hourly_counts.values,\n",
    "    title=\"Accident Frequency by Hour of Day\",\n",
    "    labels={\"x\": \"Hour of Day\", \"y\": \"Number of Accidents\"}\n",
    ")\n",
    "fig_hourly.update_layout(xaxis=dict(tickmode='linear', dtick=1))\n",
    "fig_hourly.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9399ad2",
   "metadata": {
    "id": "a9399ad2"
   },
   "source": [
    "3. Which days of the week have the highest number of accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c014d",
   "metadata": {
    "id": "cf3c014d"
   },
   "outputs": [],
   "source": [
    "# --- Question 3 Code ---\n",
    "print(\"\\n### 3. Accident Frequency by Day of the Week\")\n",
    "day_of_week_counts = df['DayOfWeek'].value_counts().sort_index()\n",
    "days = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "# Rename index for better readability\n",
    "day_of_week_counts.index = [days[i] for i in day_of_week_counts.index]\n",
    "print(\"Accident counts by Day of Week:\")\n",
    "print(day_of_week_counts)\n",
    "\n",
    "most_accident_day = day_of_week_counts.idxmax()\n",
    "print(f\"\\nThe day with the highest number of accidents is: **{most_accident_day}**\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15063162",
   "metadata": {
    "id": "15063162"
   },
   "source": [
    "4. What are the most common weather conditions during accidents?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51dea19",
   "metadata": {
    "id": "f51dea19"
   },
   "outputs": [],
   "source": [
    "# --- Question 4 Code ---\n",
    "print(\"\\n### 4. Most Common Weather Conditions During Accidents\")\n",
    "if 'Weather_Condition' in df.columns:\n",
    "    weather_counts = df['Weather_Condition'].value_counts().nlargest(5)\n",
    "    print(\"Top 5 Weather Conditions:\")\n",
    "    print(weather_counts)\n",
    "\n",
    "    # Visualization\n",
    "    fig_weather = px.pie(\n",
    "        names=weather_counts.index,\n",
    "        values=weather_counts.values,\n",
    "        title=\"Top 5 Weather Conditions During Accidents\"\n",
    "    )\n",
    "    fig_weather.show()\n",
    "else:\n",
    "    print(\"Weather_Condition column not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0adb452",
   "metadata": {
    "id": "f0adb452"
   },
   "source": [
    "5. How to identify columns with missing data and their missing percentage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1a733c",
   "metadata": {
    "id": "dd1a733c"
   },
   "outputs": [],
   "source": [
    "# --- Question 5 Code ---\n",
    "print(\"\\n### 5. Identifying Columns with Missing Data and Percentage\")\n",
    "missing_percent = round((df.isnull().sum() / df.shape[0]) * 100, 2)\n",
    "missing_info = missing_percent[missing_percent > 0].sort_values(ascending=False)\n",
    "\n",
    "print(\"Columns with missing data and their percentage (only showing > 0%):\")\n",
    "print(missing_info)\n",
    "\n",
    "columns_with_missing = missing_info.index.tolist()\n",
    "print(f\"\\nTotal columns with missing data: {len(columns_with_missing)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856274e5",
   "metadata": {
    "id": "856274e5"
   },
   "source": [
    "6. How to impute missing numerical values with median?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36247d8b",
   "metadata": {
    "id": "36247d8b"
   },
   "outputs": [],
   "source": [
    "# --- Question 6 Code ---\n",
    "print(\"\\n### 6. Imputing Missing Numerical Values with Median\")\n",
    "\n",
    "# Identify numerical columns that still have missing data\n",
    "num_cols_to_impute = df.select_dtypes(include=np.number).columns[df.select_dtypes(include=np.number).isnull().any()].tolist()\n",
    "imputed_cols_6 = []\n",
    "\n",
    "for col in num_cols_to_impute:\n",
    "    median_val = df[col].median()\n",
    "    df[col] = df[col].fillna(median_val)\n",
    "    imputed_cols_6.append(col)\n",
    "\n",
    "print(f\"Numerical imputation complete. Columns imputed: {imputed_cols_6}\")\n",
    "print(f\"Check: Missing count in 'Temperature(F)': {df['Temperature(F)'].isnull().sum()}\") # Example check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec23d938",
   "metadata": {
    "id": "ec23d938"
   },
   "source": [
    "7. How to impute missing categorical values with the mode?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe64774",
   "metadata": {
    "id": "7fe64774"
   },
   "outputs": [],
   "source": [
    "# --- Question 7 Code ---\n",
    "print(\"\\n### 7. Imputing Missing Categorical Values with Mode\")\n",
    "\n",
    "# Identify categorical (object/string) columns that still have missing data\n",
    "cat_cols_to_impute = df.select_dtypes(include=['object']).columns[df.select_dtypes(include=['object']).isnull().any()].tolist()\n",
    "imputed_cols_7 = []\n",
    "\n",
    "for col in cat_cols_to_impute:\n",
    "    # Use .mode()[0] to select the first mode in case of a tie\n",
    "    mode_value = df[col].mode()[0]\n",
    "    df[col] = df[col].fillna(mode_value)\n",
    "    imputed_cols_7.append(col)\n",
    "\n",
    "print(f\"Categorical imputation complete. Columns imputed: {imputed_cols_7}\")\n",
    "print(f\"Check: Missing count in 'Weather_Condition': {df['Weather_Condition'].isnull().sum()}\") # Example check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5fba8",
   "metadata": {
    "id": "d5c5fba8"
   },
   "source": [
    "8. How to label encode a categorical column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb7b2c",
   "metadata": {
    "id": "97eb7b2c"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- Question 8 Code ---\n",
    "print(\"\\n### 8. Label Encoding a Categorical Column\")\n",
    "\n",
    "# Example 1: Simple binary encoding for 'Sunrise_Sunset' (Day/Night)\n",
    "if \"Sunrise_Sunset\" in df.columns:\n",
    "    df[\"IsDay\"] = (df[\"Sunrise_Sunset\"] == \"Day\").astype(int)\n",
    "    print(\"1. Pandas Method: Created 'IsDay' column (0 for Night, 1 for Day) from 'Sunrise_Sunset'.\")\n",
    "    print(\"Sample of 'Sunrise_Sunset' and 'IsDay':\")\n",
    "    print(df[['Sunrise_Sunset', 'IsDay']].head())\n",
    "\n",
    "# Example 2: Using Scikit-learn's LabelEncoder (for features with many categories)\n",
    "# Using 'DayOfWeek' as an example for demonstration\n",
    "column_to_label_encode = 'DayOfWeek_Name'\n",
    "df[column_to_label_encode] = df['DayOfWeek'].apply(lambda x: days[x]) # Create the string version\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['DayOfWeek_Encoded'] = le.fit_transform(df[column_to_label_encode])\n",
    "\n",
    "print(f\"\\n2. Scikit-learn Method: Applied LabelEncoder to '{column_to_label_encode}'.\")\n",
    "print(\"Mapping (a sample):\", list(le.classes_), \"->\", list(range(len(le.classes_))))\n",
    "print(\"Sample of Original and Encoded:\")\n",
    "print(df[[column_to_label_encode, 'DayOfWeek_Encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc01b004",
   "metadata": {
    "id": "dc01b004"
   },
   "source": [
    "9. How to one-hot encode a categorical column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa1d9a1",
   "metadata": {
    "id": "8aa1d9a1"
   },
   "outputs": [],
   "source": [
    "# --- Question 9 Code ---\n",
    "print(\"\\n### 9. One-Hot Encoding a Categorical Column\")\n",
    "\n",
    "# One-hot encoding on 'DayOfWeek_Name' (the string column created in Q8)\n",
    "column_to_onehot_encode = 'DayOfWeek_Name'\n",
    "\n",
    "# Use get_dummies for one-hot encoding\n",
    "df_encoded_day = pd.get_dummies(df[column_to_onehot_encode], prefix='DOW', dummy_na=False)\n",
    "\n",
    "# Concatenate the new encoded columns back to a sample slice of the main DataFrame for display\n",
    "df_display = pd.concat([df[[column_to_onehot_encode]].head(), df_encoded_day.head()], axis=1)\n",
    "\n",
    "print(\"One-Hot Encoded DataFrame (sample of first 5 rows):\")\n",
    "print(df_display)\n",
    "\n",
    "print(f\"\\nCreated {len(df_encoded_day.columns)} new columns, e.g., {list(df_encoded_day.columns)[:3]}...\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
