{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426d9a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Load the full dataset (replace with your actual full data file path)\n",
    "full_data_path = \"C:/Users/win10/Desktop/US_Accidents_March23.csv\"\n",
    "df = pd.read_csv(full_data_path)\n",
    "\n",
    "# Sample 1 million rows (or all if dataset smaller)\n",
    "sample_size = min(1_000_000, len(df))\n",
    "df_sampled = df.sample(n=sample_size, random_state=42)  # random_state for reproducibility\n",
    "\n",
    "# Optional: reset index\n",
    "df_sampled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Save sampled data\n",
    "output_path = \"US_Accidents_March23_sampled_1M.csv\"\n",
    "df_sampled.to_csv(output_path, index=False)\n",
    "\n",
    "# print(f\"Sampled {sample_size} rows saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d6848",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('US_Accidents_March23_sampled_1M.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f2492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d59c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum() / df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb11984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns of 'End_Lat', 'End_Lng'\n",
    "df = df.drop(columns=['End_Lat', 'End_Lng'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aca1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'Start_Time' and 'End_Time' columns to datetime format\n",
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'], format='mixed')\n",
    "df['End_Time'] = pd.to_datetime(df['End_Time'], format='mixed')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5074c067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert coordinates to numeric (if not already)\n",
    "df['Start_Lat'] = pd.to_numeric(df['Start_Lat'], errors='coerce')\n",
    "df['Start_Lng'] = pd.to_numeric(df['Start_Lng'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac96ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum() / df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c730124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the rows with missing values except some columns.\n",
    "df = df.dropna(subset=['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat',\n",
    "       'Start_Lng', 'Distance(mi)', 'Description', 'Street', 'City', 'County',\n",
    "       'State', 'Zipcode', 'Country', 'Timezone', 'Airport_Code',\n",
    "       'Weather_Timestamp', 'Temperature(F)', 'Humidity(%)',\n",
    "       'Pressure(in)', 'Visibility(mi)', 'Wind_Direction','Weather_Condition', 'Amenity', 'Bump', 'Crossing',\n",
    "       'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station',\n",
    "       'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop',\n",
    "       'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
    "       'Astronomical_Twilight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b5808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum() / df.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00bb8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Wind_Chill(F)', 'Wind_Speed(mph)', 'Precipitation(in)']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[['Wind_Chill(F)', 'Wind_Speed(mph)', 'Precipitation(in)']].isnull().sum())/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2ed222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median imputation for Wind_Speed(mph)\n",
    "wind_median = df['Wind_Speed(mph)'].median()\n",
    "df['Wind_Speed(mph)'] = df['Wind_Speed(mph)'].fillna(wind_median)\n",
    "\n",
    "# Primary imputation for Precipitation(in): zero-fill\n",
    "df['Precipitation(in)'] = df['Precipitation(in)'].fillna(0.0)\n",
    "\n",
    "# Secondary imputation for known rain days: fill remaining gaps with median of nonzero precipitation\n",
    "median_nonzero_precip = df.loc[df['Precipitation(in)'] > 0, 'Precipitation(in)'].median()\n",
    "\n",
    "# Example mask for known rain days (replace with your actual condition)\n",
    "# e.g., df['Rain_Flag'] == 1 or based on another indicator column\n",
    "rain_day_mask = df['Precipitation(in)'].isna()  # placeholder if original missing flags retained\n",
    "\n",
    "# Apply secondary imputation\n",
    "df.loc[rain_day_mask, 'Precipitation(in)'] = median_nonzero_precip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Select features to predict Wind_Chill(F)\n",
    "reg_features = ['Wind_Speed(mph)', 'Temperature(F)', 'Humidity(%)']  # adjust to available predictors\n",
    "\n",
    "# Split known and unknown\n",
    "known_wc = df[df['Wind_Chill(F)'].notna()]\n",
    "unknown_wc = df[df['Wind_Chill(F)'].isna()]\n",
    "\n",
    "# Train regression model\n",
    "X_train = known_wc[reg_features]\n",
    "y_train = known_wc['Wind_Chill(F)']\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "\n",
    "# Predict missing Wind_Chill(F)\n",
    "X_pred = unknown_wc[reg_features]\n",
    "predicted_wc = reg.predict(X_pred)\n",
    "\n",
    "# Impute missing values\n",
    "df.loc[df['Wind_Chill(F)'].isna(), 'Wind_Chill(F)'] = predicted_wc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea4e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df[['Wind_Chill(F)', 'Wind_Speed(mph)', 'Precipitation(in)']].isnull().sum())/df.shape[0]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d48b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse datetimes\n",
    "df[\"Start_Time\"] = pd.to_datetime(df[\"Start_Time\"], errors=\"coerce\")\n",
    "df[\"End_Time\"]   = pd.to_datetime(df[\"End_Time\"], errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Drop duplicates and rows with invalid times\n",
    "df = df.drop_duplicates(subset=\"ID\")\n",
    "df = df.dropna(subset=[\"Start_Time\", \"End_Time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Drop rows missing critical location data\n",
    "df = df.dropna(subset=[\"Start_Lat\", \"Start_Lng\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727af48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Compute incident duration in minutes\n",
    "df[\"Duration_Minutes\"] = (df[\"End_Time\"] - df[\"Start_Time\"]).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Extract temporal features\n",
    "df[\"Hour\"]        = df[\"Start_Time\"].dt.hour\n",
    "df[\"DayOfWeek\"]   = df[\"Start_Time\"].dt.weekday\n",
    "df[\"Month\"]       = df[\"Start_Time\"].dt.month\n",
    "df[\"IsWeekend\"]   = df[\"DayOfWeek\"].isin([5,6]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c73119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Encode boolean traffic feature flags as integers\n",
    "bool_cols = [\n",
    "    \"Roundabout\",\n",
    "    \"Station\",\n",
    "    \"Stop\",\n",
    "    \"Traffic_Calming\",\n",
    "    \"Traffic_Signal\",\n",
    "    \"Turning_Loop\"\n",
    "]\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c80dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Encode light condition as binary day/night\n",
    "df[\"IsDay\"] = (df[\"Sunrise_Sunset\"] == \"Day\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef312d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Drop columns not used for modeling\n",
    "drop_cols = [\n",
    "    \"ID\",\n",
    "    \"Source\",\n",
    "    \"Description\",\n",
    "    \"Street\",\n",
    "    \"Start_Time\",\n",
    "    \"End_Time\",\n",
    "    \"Sunrise_Sunset\",\n",
    "    \"Civil_Twilight\",\n",
    "    \"Nautical_Twilight\",\n",
    "    \"Astronomical_Twilight\"\n",
    "]\n",
    "df = df.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76a14be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Handle missing values in numeric columns\n",
    "#    Fill numeric NaNs with median\n",
    "num_cols = df.select_dtypes(include=\"number\").columns.tolist()\n",
    "for col in num_cols:\n",
    "    df[col] = df[col].fillna(df[col].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfb4d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Final clean-up: remove any remaining rows with NaNs\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e112aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. stratify/drop rare severity classes if needed\n",
    "# e.g., keep only severity levels 1-4\n",
    "df = df[df[\"Severity\"].isin([1,2,3,4])]\n",
    "\n",
    "# Save cleaned dataset\n",
    "df.to_csv(\"accidents_cleaned.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
